![SeaweedFS Architecture](https://raw.githubusercontent.com/chrislusf/seaweedfs/master/note/SeaweedFS_Architecture.png)

# 文档

## 源码地址

- https://github.com/chrislusf/seaweedfs

## 作者的知乎

- https://www.zhihu.com/people/chris-lu-63

## 文档

- https://github.com/chrislusf/seaweedfs/wiki/

## docker hub镜像地址

- https://hub.docker.com/r/chrislusf/seaweedfs
- docker-compose.yaml配置模板：https://raw.githubusercontent.com/chrislusf/seaweedfs/master/docker/seaweedfs-compose.yml

# weed命令行参数

> 灵光一现。想到了lunix 的read the man。所以查看weed命令，`通过进入到docker的master容器中去，输入weed 果然有提示`。根据提示就可以看到有哪些命令，以及参数 。如 weed help [command]



```sh
## 命令行输入weed 的提示
/data # weed  
SeaweedFS: store billions of files and serve them fast!

Usage:

        weed command [arguments]

The commands are:

    autocomplete install autocomplete
    autocomplete.uninstall uninstall autocomplete
    backup      incrementally backup a volume to local folder
    benchmark   benchmark on writing millions of files and read out
    compact     run weed tool compact on volume file
    download    download files by file id
    export      list or export files from one volume data file
    filer       start a file server that points to a master server, or a list of master servers
    filer.backup resume-able continuously replicate files from a SeaweedFS cluster to another location defined in replication.toml
    filer.cat   copy one file to local
    filer.copy  copy one or a list of files to a filer folder
    filer.meta.backup continuously backup filer meta data changes to anther filer store specified in a backup_filer.toml
    filer.meta.tail see continuous changes on a filer
    filer.remote.gateway resumable continuously write back bucket creation, deletion, and other local updates to remote object store
    filer.remote.sync resumable continuously write back updates to remote storage
    filer.replicate replicate file changes to another destination
    filer.sync  resumable continuous synchronization between two active-active or active-passive SeaweedFS clusters
    fix         run weed tool fix on index file if corrupted
    fuse        Allow use weed with linux's mount command
    master      start a master server
    master.follower start a master follower
    mount       mount weed filer to a directory as file system in userspace(FUSE)
    s3          start a s3 API compatible server that is backed by a filer
    iam         start a iam API compatible server
    msgBroker   start a message queue broker
    scaffold    generate basic configuration files
    server      start a master server, a volume server, and optionally a filer and a S3 gateway
    shell       run interactive administrative commands
    upload      upload one or a list of files
    version     print SeaweedFS version
    volume      start a volume server
    webdav      start a webdav server that is backed by a filer

Use "weed help [command]" for more information about a command.

For Logging, use "weed [logging_options] [command]". The logging options are:
  -alsologtostderr
        log to standard error as well as files (default true)
  -log_backtrace_at value
        when logging hits line file:N, emit a stack trace
  -logdir string
        If non-empty, write log files in this directory
  -logtostderr
        log to standard error instead of files
  -options string
        a file of command line options, each line in optionName=optionValue format
  -stderrthreshold value
        logs at or above this threshold go to stderr
  -v value
        log levels [0|1|2|3|4], default to 0
  -vmodule value
        comma-separated list of pattern=N settings for file-filtered logging
```

## master的参数

```SH
/data # weed help master (命令行的输入)
Usage: weed master -port=9333

  start a master server to provide volume=>location mapping service and sequence number of file ids

        The configuration file "security.toml" is read from ".", "$HOME/.seaweedfs/", "/usr/local/etc/seaweedfs/", or "/etc/seaweedfs/", in that order.

        The example security.toml configuration file can be generated by "weed scaffold -config=security"


Default Parameters:
  -cpuprofile string
        cpu profile output file
  -defaultReplication string
        Default replication type if not specified.
  -disableHttp
        disable http requests, only gRPC operations are allowed.
  -garbageThreshold float
        threshold to vacuum and reclaim spaces (default 0.3)
  -ip string
        master <ip>|<server> address, also used as identifier (default "172.19.0.3")
  -ip.bind string
        ip address to bind to
  -mdir string
        data directory to store meta data (default "/tmp")
  -memprofile string
        memory profile output file
  -metrics.address string
        Prometheus gateway address <host>:<port>
  -metrics.intervalSeconds int
        Prometheus push interval in seconds (default 15)
  -peers string
        all master nodes in comma separated ip:port list, example: 127.0.0.1:9093,127.0.0.1:9094,127.0.0.1:9095
  -port int
        http listen port (default 9333)
  -port.grpc int
        grpc listen port
  -resumeState
        resume previous state on start master server
  -volumePreallocate
        Preallocate disk space for volumes.
  -volumeSizeLimitMB uint
        Master stops directing writes to oversized volumes. (default 30000)
  -whiteList string
        comma separated Ip addresses having write permission. No limit if empty.

```

## volume的参数

```SH
/data # weed help volume
Usage: weed volume -port=8080 -dir=/tmp -max=5 -ip=server_name -mserver=localhost:9333

  start a volume server to provide storage spaces


Default Parameters:
  -compactionMBps int
        limit background compaction or copying speed in mega bytes per second
  -concurrentDownloadLimitMB int
        limit total concurrent download size (default 256)
  -concurrentUploadLimitMB int
        limit total concurrent upload size (default 256)
  -cpuprofile string
        cpu profile output file
  -dataCenter string
        current volume server's data center name
  -dir string
        directories to store data files. dir[,dir]... (default "/tmp")
  -dir.idx string
        directory to store .idx files
  -disk string
        [hdd|ssd|<tag>] hard drive or solid state drive or any tag
  -fileSizeLimitMB int
        limit file size to avoid out of memory (default 256)
  -idleTimeout int
        connection idle seconds (default 30)
  -images.fix.orientation
        Adjust jpg orientation when uploading.
  -index string
        Choose [memory|leveldb|leveldbMedium|leveldbLarge] mode for memory~performance balance. (default "memory")
  -ip string
        ip or server name, also used as identifier (default "172.19.0.3")
  -ip.bind string
        ip address to bind to
  -max string
        maximum numbers of volumes, count[,count]... If set to zero, the limit will be auto configured. (default "8")
  -memprofile string
        memory profile output file
  -metricsPort int
        Prometheus metrics listen port
  -minFreeSpace string
        min free disk space (value<=100 as percentage like 1, other as human readable bytes, like 10GiB). Low disk space will mark all volumes as ReadOnly.
  -minFreeSpacePercent string
        minimum free disk space (default to 1%). Low disk space will mark all volumes as ReadOnly (deprecated, use minFreeSpace instead). (default "1")
  -mserver string
        comma-separated master servers (default "localhost:9333")
  -port int
        http listen port (default 8080)
  -port.grpc int
        grpc listen port
  -port.public int
        port opened to public
  -pprof
        enable pprof http handlers. precludes --memprofile and --cpuprofile
  -preStopSeconds int
        number of seconds between stop send heartbeats and stop volume server (default 10)
  -publicUrl string
        Publicly accessible address
  -rack string
        current volume server's rack name
  -readMode string
        [local|proxy|redirect] how to deal with non-local volume: 'not found|proxy to remote node|redirect volume location'. (default "proxy")
  -tcp
        <exprimental> enable tcp port
  -whiteList string
        comma separated Ip addresses having write permission. No limit if empty.
```

## filer的参数

```SH
/data # weed help filer
Usage: weed filer -port=8888 -master=<ip:port>[,<ip:port>]*

  start a file server which accepts REST operation for any files.

        //create or overwrite the file, the directories /path/to will be automatically created
        POST /path/to/file
        //get the file content
        GET /path/to/file
        //create or overwrite the file, the filename in the multipart request will be used
        POST /path/to/
        //return a json format subdirectory and files listing
        GET /path/to/

        The configuration file "filer.toml" is read from ".", "$HOME/.seaweedfs/", "/usr/local/etc/seaweedfs/", or "/etc/seaweedfs/", in that order.
        If the "filer.toml" is not found, an embedded filer store will be created under "-defaultStoreDir".

        The example filer.toml configuration file can be generated by "weed scaffold -config=filer"


Default Parameters:
  -collection string
        all data will be stored in this default collection
  -concurrentUploadLimitMB int
        limit total concurrent upload size (default 128)
  -dataCenter string
        prefer to read and write to volumes in this data center
  -debug
        serves runtime profiling data, e.g., http://localhost:<debug.port>/debug/pprof/goroutine?debug=2
  -debug.port int
        http port for debugging (default 6060)
  -defaultReplicaPlacement string
        default replication type. If not specified, use master setting.
  -defaultStoreDir string
        if filer.toml is empty, use an embedded filer store in the directory (default ".")
  -dirListLimit int
        limit sub dir listing size (default 100000)
  -disableDirListing
        turn off directory listing
  -disableHttp
        disable http request, only gRpc operations are allowed
  -encryptVolumeData
        encrypt data on volume servers
  -iam
        whether to start IAM service
  -iam.port int
        iam server http listen port (default 8111)
  -ip string
        filer server http listen ip address (default "172.19.0.3")
  -ip.bind string
        ip address to bind to
  -master string
        comma-separated master servers (default "localhost:9333")
  -maxMB int
        split files larger than the limit (default 4)
  -metricsPort int
        Prometheus metrics listen port
  -port int
        filer server http listen port (default 8888)
  -port.grpc int
        filer server grpc listen port
  -port.readonly int
        readonly port opened to public
  -rack string
        prefer to write to volumes in this rack
  -s3
        whether to start S3 gateway
  -s3.allowEmptyFolder
        allow empty folders (default true)
  -s3.cert.file string
        path to the TLS certificate file
  -s3.config string
        path to the config file
  -s3.domainName string
        suffix of the host name in comma separated list, {bucket}.{domainName}
  -s3.key.file string
        path to the TLS private key file
  -s3.port int
        s3 server http listen port (default 8333)
  -saveToFilerLimit int
        files smaller than this limit will be saved in filer store
  -webdav
        whether to start webdav gateway
  -webdav.cacheCapacityMB int
        local cache capacity in MB (default 1000)
  -webdav.cacheDir string
        local cache directory for file chunks (default "/tmp")
  -webdav.cert.file string
        path to the TLS certificate file
  -webdav.collection string
        collection to create the files
  -webdav.disk string
        [hdd|ssd|<tag>] hard drive or solid state drive or any tag
  -webdav.key.file string
        path to the TLS private key file
  -webdav.port int
        webdav server http listen port (default 7333)
  -webdav.replication string
        replication to create the files
```

# 文档摘要

## Getting Started

### Installing SeaweedFS

> 下载地址：https://github.com/chrislusf/seaweedfs/releases.

- darwin 对应mac， amd->x86(intel)
- 所以老mac下载darwin_amd64.tar.gz
- windows 下载：windows_amd64_large_disk.zip

## Master API

> 文档：https://github.com/chrislusf/seaweedfs/wiki/Master-Server-API

### Assign a file key

```
http://192.168.50.105:9333/dir/assign
```

### Check Volume Status（检查卷的状态 ）

```
http://192.168.50.105:9333/vol/status?pretty=y
```

### Check System Status（检查系统状态）

```
http://192.168.50.105:9333/cluster/status?pretty=y
```

### Check Writable Volume Status（检查可写卷的状态）

```
http://192.168.50.105:9333/dir/status?pretty=y
```

### Lookup volume（查找卷）

```
http://192.168.50.105:9333/dir/lookup?volumeId=3&pretty=y
```

## Filer Server API

- 上传文件。 filename不写的话，文件名就是真实的文件名，写了文件浏览器显示的就是指定的filename，path是指定的路径（不存在会自动创建），path后面要跟`/`，否则 path就会被认为是filename，文件会上传在根目录

```sh
# post
http://192.168.50.105:8889/path/filename
```

- op=append 意思为：向filename文件末尾追加内容。应该是同样的文件格式追加才有意义

```SH
#POST
http://192.168.50.105:8889/path/filename?op=append
```



- 查询某个文件夹下的文件列表。注意：请求头需要加上`accept: application/json`。否则，默认返回的是html

```
# get
curl -H "Accept: application/json" "http://localhost:8888/javascript/?pretty=y"  
```



## Configuration（配置）

### Replication（复制策略）

| Value | Meaning                                                      |
| ----- | ------------------------------------------------------------ |
| 000   | no replication, just one copy                                |
| 001   | replicate once on the same rack                              |
| 010   | `replicate once on a different rack in the same data center` |
| 100   | replicate once on a different data center                    |
| 200   | replicate twice on two other different data center           |
| 110   | replicate once on a different rack, and once on a different data centÍer |
| ...   | ...                                                          |

#### 文件上传的步骤

1. 客户端发送一个指定复制策略（策略可选）的请求到master，为了获取fid
2. master接手到了分配fid的请求，取决于不同的复制策略，master会选择volume服务来处理这次请求，并返回fid和volume服务器的url给客户端
3. 客户端携带分配的fid，上传文件到分配的volume服务
4. volume服务持久化文件，并执行指定的复制策略
5. 所有事情完成，客户端得到成功的响应

#### Fix replication（修复副本）

- 如果一个副本丢失，weedfs不会自动修复。这是因为防止 卷服务器短暂的失败或者断开连接。与此同时，卷服务会变成只读，如果有新的写入请求，master会分配给别的卷服务。
- 如果要修复，可以在weed 脚本上执行 volume.fix.replication

#### Change replication（改变副本策略）

- 在weed脚本上执行 volume.configure.replication 。然后在执行volume.fix.replication 修复丢失的副本

### GRCP端口 默认是端口+10000

##  Security（加密访问）

### [Security Overview](https://github.com/chrislusf/seaweedfs/wiki/Security-Overview)

> 写的很详细，步骤很明确，建议反复阅读。仔细阅读`Security Overview`和`security.toml`

- 重点：支持jwt访问volume和filer。
- master不支持jwt校验请求头，但是请求master，master会自己生成token。
- weed filer（2.84版本） 通过单独配置（jwt.filer_signing.read.key）支持请求读文件时jwt校验，而支持http：upload/update/delete 操作的JWT校验

### How JWT-based access control works （jwt在weedfs中怎么做访问控制）

- 比如上传一个文件，通过`http://<master>:<port>/dir/assign`申请一个fid，master将根据`jwt.signing.key`生成一个jwt，并添加到这个请求的响应头（Authorization：BEARER xxxx）上，token的有效期默认10秒钟。

- 客户端从响应头中读取token，在请求volume时候请求头（Authorization）携带此token，完成`upload/update/delete`文件的动作。

- 设置了`jwt.signing.key`，默认通过浏览器访问volume的页面（如：http://192.168.51.34:9381/ui/index.html）是禁用的，通过在配置文件`security.toml`中添加access.ui=true，来允许WEB访问。见配置文件：`/Users/yuzhiming/Documents/docker/weedfs_replication/security.toml`

- 补充说明：

  - `请求master是无需携带token的`。意味着通过`http://<master>:<port>/submit`上传文件不校验token的。

  - 目的还是为了保护volume服务，毕竟数据在volume上，而master是没有数据的。master的角色更多的充当一个类似于业务应用。

  - 要想从volume服务器`read`文件`校验token`话，需要设置如下。见配置文件

    ```sh
    [jwt.signing.read]
    key = ""
    expires_after_seconds = 10           # seconds
    ```

### 总结

- 通过命令生成weedfs配置文件

  ```sh
  # 输出的是文本，需要自己新建security.toml，并将内容拷贝到这个文件
  weed scaffold -config=security
  ```

- 配置security.toml。（通过阅读security.toml文件的注释，以及Security Overview）

- 将该配置文件放到以下三个当中的任意一个地方，优先级从高到低

  ```sh
  ./security.toml
  $HOME/.seaweedfs/security.toml
  #由于我是docker compose部署，因此我将此文件放在了docker-compose.yaml文件同目录下，并映射到容器中的以下文件
  /etc/seaweedfs/security.toml
  ```

## Filer

> 个人感觉是一个`文件浏览器`。通过POST请求`http://localhost:8888/由客户端指定上传的目录（不存在则会创建）/"`（路径最后要带`/`）。Filer会返回`{name:'文件名称',size：文件大小 }`格式的响应体。通过GET请求`http://localhost:8888/目录/文件名`来查看文件。
>
> 会与master建立一个`长链接`。最终文件还是会保存到volume服务器。Filer会保存的文件`元数据（metadata）`。元数据有多种保存方式：本地磁盘（默认）、mysql、redis等等

- 通过`weed scaffold -config=filer`生成Filer的配置文件`filer.toml`。
- 仔细阅读此配置文件，存放位置与security.toml一致。通过此配置文件可以更改元数据的存储方式。

### Data Structure for Large Files

> `对小文件、中文件、大文件、超大文件做了介绍，并给出了一些文件大小定量的区分`

## WebDAV协议

> **[WebDAV](https://www.jianguoyun.com/)** ，全称是Web-based Distributed Authoring and Versioning 。基于Web的分布式编写和版本控制（WebDAV）是超文本传输协议（HTTP）的扩展，有利于用户间协同编辑和管理存储在万维网服务器文档。

- 当前weedfs对WebDAV的是实现是`不支持身份验证的`。
- 按照文档操作使用mac的Finder的`连接服务器`功能是`连接不上的`。但是通过`window10是可以的`，
  - 打开`我的电脑`
  - 右击`添加一个网络位置`
  - 在`Intennet地址或网络地址`栏输入`http://10.1.20.177:7333/`。（这里的ip地址是我测试的地址，正式应该换成weedfs webdav server的ip地址）
  - 成功。

## [FUSE Mount](https://github.com/chrislusf/seaweedfs/wiki/FUSE-Mount)

> FUSE文件系统介绍参考博文：https://www.jianshu.com/p/c2b77d0bbc43。
>
> 全称：Filesystem in Userspace（即在**用户空间**的文件系统）

- seaweedfs支持可以`lunix ，mac OS` ，mac需要安装`macfuse-4.3.1.dmg`(下载地址：https://github.com/osxfuse/osxfuse/releases)

- 需要下载weed命令（见Getting Started）

  ```SH
  ./weed mount -filer=localhost:8888 -dir=/Users/yuzhiming/Downloads/weeddir -filer.path=/
  ```

- 挂载成功。但是不能往里拷贝文件，原因是因为在security.toml配置了volume server的oauth2秘钥，置空就成功了。可以往挂载点写文件

## Use Cases（用户案例）

### Saving image with different sizes（保存一张图片的不同尺寸）

```sh
curl http://<host>:<port>/dir/assign?count=5
{"fid":"3,01637037d6","url":"127.0.0.1:8080","publicUrl":"localhost:8080","count":5}

# 上传
http://<url>:<port>/3,01637037d6
http://<url>:<port>/3,01637037d6_1
http://<url>:<port>/3,01637037d6_2
http://<url>:<port>/3,01637037d6_3
http://<url>:<port>/3,01637037d6_4
```

### Overwriting mime types（重写mime类型）

```sh
curl -F "file=@myImage.png;type=image/png" http://127.0.0.1:8081/5,2730a7f18b44
```

### Securing SeaweedFS （通过设置白名单安全访问SeaweedFs）

```sh
weed master -whiteList="::1,127.0.0.1"
weed volume -whiteList="::1,127.0.0.1"
# "::1" is for IP v6 localhost.
```

### Data Migration Example（数据移动案例）

- 直接可以将一个volume服务data目录下的数据 移动到 另一个volume服务data目录下

## Operations

### [System Metrics](https://github.com/chrislusf/seaweedfs/wiki/System-Metrics)

> SeaweedFS利用[Prometheus](https://prometheus.io/)存储监控指标和[Grafana](https://grafana.com/grafana) 做可视化。
>
> SeaweedFS同时支持推送和拉取指标。
>
> 一键部署Prometheus等监控系统参考：https://github.com/evnsio/prom-stack
>
> 关于Prometheus配置参考：/Users/yuzhiming/workspace/seaweedfs/docker/prometheus/prometheus.yml

- grafana新建仪表盘大致操作
  - 仪表盘市场：https://grafana.com/grafana/dashboards/10423。
    - 作者放在了github：https://github.com/chrislusf/seaweedfs/blob/master/other/metrics/grafana_seaweedfs.json
  - 配置prometheus数据源
  - 选择important，导入仪表盘。id就是10423。

## Advanced（先进的）

### Large File Handling

> `介绍了weedfs如何真实处理大文件（很详细）`
>
> 文档地址：https://github.com/chrislusf/seaweedfs/wiki/Large-File-Handling

- 为了支持大文件，有两种文件类型

  - Chunk File. Each chunk file is actually just normal files to SeaweedFS.
  - Chunk Manifest. A simple json file with the list of all the chunks.

  #### Create new large file

  `以下步骤会委托客户端来做（执行weed upload命令所在的客户端），以下记录了weedfs真实处理大文件的思路`

  - 将大文件拆分成多个小文件
  - 逐个上传小文件（每个小文件可能会被上传到不同的volume，同样这也可以提交下载的并发量）
  - 创建一个manifest.json记录之前上传的所有fid
  - 最后将这个manifest.json文件上传

  #### note

  至于将大文件拆分成多少个小文件，这个没有定论。根据经验法则的话，是可以让一个chunk 文件完全读入内存，但是也不要拆分成太多的chunk文件，两者之间取一个平衡吧。

  #### weed filer and weed mount

  > `对于调用服务上传的方式，而不知执行weed upload命令来上传大文件，那么谁来将大文件拆分成小文件呢`

  是有filer来进行拆分的。The list of chunks are stored in filer storage, and managed by filer or weed mount client.

## 未知地方的

### 修复volume索引

- 从小文件版本 切换到large_disk版本，需要重新创建volume下*.idx

  ```sh
   .\weed.exe fix -dir=D:\docker\weedfs_replication\data2  -volumeId=8
  ```

# 问题解决

## 使用docker的 chrislusf/seaweedfs:2.78镜像是可以，使用3.06版本的镜像是不行的，无法启动master



## `使用自定义的env_file，名字叫：my.env。在docker-compose.yaml使用${}取环境变量的值，取不到`

- 解决方式参考https://forums.docker.com/t/variables-resolved-from-env-file-but-not-taking-effect-in-docker-compose-yaml/105394/2。`我在docker-docs文档中也描述了此问题`。

## 使用windows10连接webdav提示无法访问，但是mac可以连接

- 通过观察webdav服务的日志，发现是`定位某些文件失败导致的`。

  ```SH
  docker logs -f --tail 200 weedfs-webdav-1
  ```

  - 错误日志

  ```
  I0607 00:46:01     1 reader_at.go:57] failed to locate 5,5cb1fdc1a2
  E0607 00:46:01     1 filechunk_manifest.go:98] operation LookupFileId 5,5cb1fdc1a2 failed, err: failed to loc
  ate 5,5cb1fdc1a2
  E0607 00:46:01     1 reader_at.go:150] fetching chunk &{FileId:5,5cb1fdc1a2 Offset:0 Size:258 LogicOffset:0 C
  hunkSize:258 CipherKey:[] IsGzipped:true}: failed to locate 5,5cb1fdc1a2
  E0607 00:46:01     1 webdav_server.go:557] file read /nas.webloc: failed to locate 5,5cb1fdc1a2
  2022/06/07 00:46:01 http: superfluous response.WriteHeader call from golang.org/x/net/webdav.(*Handler).Serve
  HTTP (webdav.go:74)
  I0607 00:46:01     1 reader_at.go:57] failed to locate 5,5cb1fdc1a2
  E0607 00:46:01     1 filechunk_manifest.go:98] operation LookupFileId 5,5cb1fdc1a2 failed, err: failed to loc
  ate 5,5cb1fdc1a2
  E0607 00:46:01     1 reader_at.go:150] fetching chunk &{FileId:5,5cb1fdc1a2 Offset:0 Size:258 LogicOffset:0 C
  hunkSize:258 CipherKey:[] IsGzipped:true}: failed to locate 5,5cb1fdc1a2
  E0607 00:46:01     1 webdav_server.go:557] file read /nas.webloc: failed to locate 5,5cb1fdc1a2
  2022/06/07 00:46:01 http: superfluous response.WriteHeader call from golang.org/x/net/webdav.(*Handler).Serve
  HTTP (webdav.go:74)
  ```

  ## 调用weed upload上传文件夹的文件，上传成功 ，查看时报错400

> 文件：/Users/yuzhiming/Documents/docker/weedfs_replication/cmd/mac/upload.sh
>
> `要注意：要使用对应服务端版本的命令。比如large_dis要对应相应的命令`

- 原来的命令，查看时报400。应该是不能加上-debug

```sh
./weed upload -master=192.168.50.105:9333 -dir=/Users/yuzhiming/Downloads/nginx-1.20.2 -collection=uploadByMacTest -ttl=3m -debug > ./$(date "+%Y%m%d-%H%M%S").log
```

- 换成以下正确了

```sh
./weed upload -master=192.168.50.105:9333 -dir=/Users/yuzhiming/Downloads/nginx-1.20.2 -collection=uploadByMacTest -ttl=1y > ./$(date "+%Y%m%d-%H%M%S").log
```

## 通过weed upload命令批量上传文件设置了collection，但是weedfs master没有提供根据collection查找fid的api

- 在批量上传完成之后，将保存fid的日志文件也上传，最终持久化保存一个日志文件fid